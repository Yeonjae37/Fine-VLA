{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a64093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\Fine-VLA\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\Documents\\Fine-VLA\\.venv\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######USING ATTENTION STYLE:  frozen-in-time\n"
     ]
    }
   ],
   "source": [
    "import autorootcwd\n",
    "from src.model.model import FrozenInTime, compute_similarity\n",
    "from src.data.data_loader import TextVideoDataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_loader = TextVideoDataLoader(\n",
    "    dataset_name= \"NTU\",\n",
    "    text_params= {\"input\": \"text\",},\n",
    "    video_params= {\"input_res\": 224, \"num_frames\": 4,},\n",
    "    data_dir= \"data/nturgbd\",\n",
    "    metadata_dir= \"data/nturgbd\",\n",
    "    split= 'train',\n",
    "    tsfm_params= None,\n",
    "    tsfm_split= None,\n",
    "    cut= None,\n",
    "    subsample= 1,\n",
    "    sliding_window_stride= -1,\n",
    "    reader= 'decord',\n",
    "    batch_size=32,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "model = FrozenInTime(\n",
    "    video_params={\"model\": \"SpaceTimeTransformer\", \"num_frames\": 4, \"arch_config\":\"base_patch16_224\", \"vit_init\": \"imagenet-21k\", \"attention_style\":\"frozen-in-time\", \"pretrained\":True},\n",
    "    text_params={\"model\": \"distilbert-base-uncased\", \"pretrained\": True},\n",
    "    projection_dim=256,\n",
    ").to(device)\n",
    "\n",
    "for p in model.video_model.parameters(): p.requires_grad=False\n",
    "for p in model.text_model.parameters():  p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4937b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "batch = next(iter(data_loader))\n",
    "video_data = batch['video'].to(device)\n",
    "text_data = tokenizer(\n",
    "    batch['text'],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=tokenizer.model_max_length\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2294530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01 — loss: 0.0243\n",
      "Step 02 — loss: -0.5016\n",
      "Step 03 — loss: -0.6397\n",
      "Step 04 — loss: -0.7773\n",
      "Step 05 — loss: -0.8865\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(5):\n",
    "    # 1. forward\n",
    "    video_embeddings = model.compute_video(video_data)\n",
    "    text_embeddings  = model.compute_text(text_data)\n",
    "\n",
    "    # 2. positive 유사도만 뽑아서 loss 정의\n",
    "    _, pos_sims = compute_similarity(video_embeddings, text_embeddings)\n",
    "    loss = - pos_sims.mean()\n",
    "\n",
    "    # 3. backward & step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step {i+1:02d} — loss: {loss.item():.4f}\")\n",
    "    \n",
    "torch.save(model.state_dict(), \"finetuned_head.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cbaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0/10 finished, average loss = 3.4658 ---\n",
      "Saved checkpoint to finetuned_epoch1.pkl\n",
      "--- Epoch 1/10 finished, average loss = 3.4155 ---\n",
      "Saved checkpoint to finetuned_epoch2.pkl\n",
      "--- Epoch 2/10 finished, average loss = 3.3378 ---\n",
      "Saved checkpoint to finetuned_epoch3.pkl\n",
      "--- Epoch 3/10 finished, average loss = 3.1951 ---\n",
      "Saved checkpoint to finetuned_epoch4.pkl\n",
      "--- Epoch 4/10 finished, average loss = 3.0604 ---\n",
      "Saved checkpoint to finetuned_epoch5.pkl\n",
      "--- Epoch 5/10 finished, average loss = 2.9387 ---\n",
      "Saved checkpoint to finetuned_epoch6.pkl\n",
      "--- Epoch 6/10 finished, average loss = 2.8747 ---\n",
      "Saved checkpoint to finetuned_epoch7.pkl\n",
      "--- Epoch 7/10 finished, average loss = 2.8019 ---\n",
      "Saved checkpoint to finetuned_epoch8.pkl\n",
      "--- Epoch 8/10 finished, average loss = 2.7584 ---\n",
      "Saved checkpoint to finetuned_epoch9.pkl\n",
      "--- Epoch 9/10 finished, average loss = 2.7094 ---\n",
      "Saved checkpoint to finetuned_epoch10.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for p in model.video_model.parameters(): p.requires_grad = False\n",
    "for p in model.text_model.parameters():  p.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "temperature = 0.07\n",
    "\n",
    "num_epochs = 10\n",
    "log_interval = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    epoch_loss   = 0.0\n",
    "    num_batches  = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(data_loader, start=1):\n",
    "        video_data = batch[\"video\"].to(device)\n",
    "        text_data = tokenizer(\n",
    "            batch['text'],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=tokenizer.model_max_length\n",
    "        ).to(device)\n",
    "\n",
    "        video_embeddings = model.compute_video(video_data)\n",
    "        text_embeddings = model.compute_text(text_data)\n",
    "\n",
    "        sim, _ = compute_similarity(video_embeddings, text_embeddings)\n",
    "        labels = torch.arange(sim.size(0), device=device)\n",
    "\n",
    "        loss_v2t = F.cross_entropy(sim / temperature, labels)\n",
    "        loss_t2v = F.cross_entropy(sim.t() / temperature, labels)\n",
    "        loss = (loss_v2t + loss_t2v) / 2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss   += loss.item()\n",
    "        num_batches  += 1\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            avg = running_loss / log_interval\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}  Batch {batch_idx}]  loss = {avg:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_avg = epoch_loss / num_batches\n",
    "    print(f\"--- Epoch {epoch}/{num_epochs} finished, average loss = {epoch_avg:.4f} ---\")\n",
    "\n",
    "    ckpt = {\"state_dict\": model.state_dict()}\n",
    "    ckpt_path = f\"finetuned_epoch{epoch+1}.pkl\"\n",
    "    with open(ckpt_path, \"wb\") as f:\n",
    "        pickle.dump(ckpt, f)\n",
    "\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fine-VLA",
   "language": "python",
   "name": "fine-vla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
