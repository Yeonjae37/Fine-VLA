{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a64093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######USING ATTENTION STYLE:  frozen-in-time\n"
     ]
    }
   ],
   "source": [
    "import autorootcwd\n",
    "from src.model.model import FrozenInTime, compute_similarity\n",
    "from src.data.data_loader import TextVideoDataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_loader = TextVideoDataLoader(\n",
    "    dataset_name= \"NTU\",\n",
    "    text_params= {\"input\": \"text\",},\n",
    "    video_params= {\"input_res\": 224, \"num_frames\": 4,},\n",
    "    data_dir= \"data/nturgbd\",\n",
    "    metadata_dir= \"data/nturgbd\",\n",
    "    split= 'train',\n",
    "    tsfm_params= None,\n",
    "    tsfm_split= None,\n",
    "    cut= None,\n",
    "    subsample= 1,\n",
    "    sliding_window_stride= -1,\n",
    "    reader= 'decord',\n",
    "    batch_size=32,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "model = FrozenInTime(\n",
    "    video_params={\"model\": \"SpaceTimeTransformer\", \"num_frames\": 4, \"arch_config\":\"base_patch16_224\", \"vit_init\": \"imagenet-21k\", \"attention_style\":\"frozen-in-time\", \"pretrained\":True},\n",
    "    text_params={\"model\": \"distilbert-base-uncased\", \"pretrained\": True},\n",
    "    projection_dim=256,\n",
    ").to(device)\n",
    "\n",
    "for p in model.video_model.parameters(): p.requires_grad=False\n",
    "for p in model.text_model.parameters():  p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4937b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\Fine-VLA\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "batch = next(iter(data_loader))\n",
    "video_data = batch['video'].to(device)\n",
    "text_data = tokenizer(\n",
    "    batch['text'],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=tokenizer.model_max_length\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2294530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01 — loss: 0.0243\n",
      "Step 02 — loss: -0.5016\n",
      "Step 03 — loss: -0.6397\n",
      "Step 04 — loss: -0.7773\n",
      "Step 05 — loss: -0.8865\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(5):\n",
    "    # 1. forward\n",
    "    video_embeddings = model.compute_video(video_data)\n",
    "    text_embeddings  = model.compute_text(text_data)\n",
    "\n",
    "    # 2. positive 유사도만 뽑아서 loss 정의\n",
    "    _, pos_sims = compute_similarity(video_embeddings, text_embeddings)\n",
    "    loss = - pos_sims.mean()\n",
    "\n",
    "    # 3. backward & step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step {i+1:02d} — loss: {loss.item():.4f}\")\n",
    "    \n",
    "torch.save(model.state_dict(), \"finetuned_head.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "log_interval = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, batch in enumerate(data_loader, start=1):\n",
    "        video_data = batch[\"video\"].to(device)\n",
    "        text_data = tokenizer(\n",
    "            batch['text'],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=tokenizer.model_max_length\n",
    "        ).to(device)\n",
    "\n",
    "        video_embeddings = model.compute_video(video_data)\n",
    "        text_embeddings = model.compute_text(text_data)\n",
    "\n",
    "        _, pos_sims = compute_similarity(video_embeddings, text_embeddings)\n",
    "        loss = -pos_sims.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            avg = running_loss / log_interval\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}  Batch {batch_idx}]  loss = {avg:.4f}\")\n",
    "            running_loss = 0.0\n",
    "    torch.save(model.state_dict(), f\"finetuned_epoch{epoch+1}.pth\")\n",
    "    print(f\"Finished epoch {epoch+1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33639a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fine-VLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
